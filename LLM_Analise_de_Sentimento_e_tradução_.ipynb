{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOWXNEWW+wv5gJSnPdQhbYe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danilomennezes/LLM-PLN/blob/main/LLM_Analise_de_Sentimento_e_tradu%C3%A7%C3%A3o_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LLM - Classificação de Sentimento, com comentários do YOUTUBE\n",
        "\n",
        "Apresntação para alunos do Curso de Ciencias da Computação da UNESP de São José do Rio Preto.\n",
        "\n",
        "API do HUGGINGFACE para classificar sentimentos e Traduzir texto.\n",
        "\n",
        "API do Youtube para buscar os comentários\n"
      ],
      "metadata": {
        "id": "b5mPiC7gMkd-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "https://huggingface.co/\n",
        "\n"
      ],
      "metadata": {
        "id": "cu141A5ERZ7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Substitua o 'xxxxxxxxxxxxxxxxxxx' com o seu token, adquirido em https://huggingface.co/\n",
        "headers = {\"Authorization\": f\"Bearer hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}"
      ],
      "metadata": {
        "id": "fMDFbrbnAdFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exemplo Inicial disponivel na documentação do Huggingface\n",
        "#Classificar sentimento\n",
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "#headers = {\"Authorization\": \"Bearer hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"eu gostei do filme\",\n",
        "})\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "zaVWdDAHfJkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resumir texto\n",
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"\n",
        "\n",
        "#headers = {\"Authorization\": \"Bearer hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Os LLMs são treinados em grandes conjuntos de dados para reconhecer e gerar texto, entre outras tarefas. Eles usam técnicas de Machine Learning (ML) para entender e gerar linguagem humana, como textos e imagens. Os LLMs podem ser adaptados para lidar com domínios específicos, como medicina ou direito.\",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "id": "D1AeaYkDEE-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Traduzir\n",
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/facebook/mbart-large-50-many-to-many-mmt\"\n",
        "\n",
        "#headers = {\"Authorization\": \"Bearer hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"i want water\",\n",
        "    \"parameters\": {\n",
        "        \"src_lang\": \"en_XX\",\n",
        "        \"tgt_lang\": \"pt_XX\"\n",
        "    }\n",
        "})\n",
        "\n",
        "print(output)\n",
        "#print(output[0]['translation_text'])"
      ],
      "metadata": {
        "id": "iMYvFDZP-WAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iniciando a Aplicação"
      ],
      "metadata": {
        "id": "TC1bjkQ1HVKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##API YouTube\n",
        "Iremos criar uma API para buscar os comentários do Youtube através do ID escolhido\n"
      ],
      "metadata": {
        "id": "pPJCrTOiM37M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7MwzRpm_0We"
      },
      "outputs": [],
      "source": [
        "pip install google-api-python-client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Substitua o 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxx' com o seu token\n",
        "api_yt = 'xxxxxxxxxxxxxxxxx'"
      ],
      "metadata": {
        "id": "0MBjqRMmBAIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=0IfuDA1edcE\n"
      ],
      "metadata": {
        "id": "iCaoD5QHKKlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build #serviço da API do YouTube.\n",
        "\n",
        "api_key = api_yt\n",
        "video_id = '0IfuDA1edcE'\n",
        "\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "# Função para pegar comentários\n",
        "def get_comments(video_id):\n",
        "    comments = []\n",
        "    response = youtube.commentThreads().list(\n",
        "        part='snippet',\n",
        "        videoId=video_id,\n",
        "        maxResults=100,  # Número máximo de resultados por chamada\n",
        "        textFormat='plainText'\n",
        "    ).execute()\n",
        "\n",
        "    while response:\n",
        "        for item in response['items']:\n",
        "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
        "            comments.append(comment)\n",
        "\n",
        "        # Verifica se há uma próxima página de resultados\n",
        "        if 'nextPageToken' in response:\n",
        "            response = youtube.commentThreads().list(\n",
        "                part='snippet',\n",
        "                videoId=video_id,\n",
        "                pageToken=response['nextPageToken'],\n",
        "                maxResults=100,\n",
        "                textFormat='plainText'\n",
        "            ).execute()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n"
      ],
      "metadata": {
        "id": "o2U_p9s7AfDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chamada da função para API Youtube\n",
        "comments = get_comments(video_id)\n",
        "for i, comment in enumerate(comments, 1):\n",
        "    print(f'Comment {i}: {comment}')"
      ],
      "metadata": {
        "id": "5agRUD69C71B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificando a estrutura da resposa\n",
        "print(comments['items'][1]['snippet']['topLevelComment']['snippet']['textOriginal'])"
      ],
      "metadata": {
        "id": "-EA7L7zZk7Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instanciando a biblioteca pandas para inserir os dados em uma tabela\n",
        "import pandas as pd\n",
        "comentarios_yt = pd.DataFrame(comments)\n",
        "comentarios_yt"
      ],
      "metadata": {
        "id": "7wQAF6zgAfSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##API Classificar Sentimento\n",
        "Criaremos uma função para analisar cada comentário recebido da API do YouTube"
      ],
      "metadata": {
        "id": "E_gTNkt6JH0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Função para acessar API Hugging Face e analisar os comentários\n",
        "\n",
        "import requests #Bibliotca para fazer requisições\n",
        "API_URL = \"https://api-inference.huggingface.co/models/distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "def inserir_comentario(comentario):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=comentario) #função do HuggingFace\n",
        "\treturn response.json()"
      ],
      "metadata": {
        "id": "tTGx3jGMLpR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Função para percorrer lista de comentários e chamar a funç~]ao de analise\n",
        "def classificar_sentimentos(text):\n",
        "  comentario = {\"inputs\": text}\n",
        "  response = inserir_comentario(comentario) # chamada da função 'inserir_comentario' para acessar a API da Hugging Face\n",
        "  #try:\n",
        "  if response[0][0]['label'] == 'POSITIVE': # classificando os comentários\n",
        "    return 'Positivo'\n",
        "  else:\n",
        "    return 'Negativo'"
      ],
      "metadata": {
        "id": "nrMScU_RfX0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comentarios_amostra = comentarios_yt[10:20] #Criando uma nova tabela, com uma amostra dos dados"
      ],
      "metadata": {
        "id": "7Ul0_u5agHNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comentarios_amostra['classificação'] = comentarios_amostra[0].apply(classificar_sentimentos) #Insere uma nova coluna na tabela, com o resultado da função classificar_sentimentos"
      ],
      "metadata": {
        "id": "5HS6iFKTgOPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comentarios_amostra"
      ],
      "metadata": {
        "id": "nqvP1GNIgrhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##API Traduzir Texto\n",
        "Criaremos uma função para Traduzir cada comentário recebido da API do YouTube"
      ],
      "metadata": {
        "id": "n9VMrNQeJBxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Traduzir texto\n",
        "#Função para acessar API Hugging Face\n",
        "import requests #Bibliotca para fazer requisições\n",
        "API_URL = \"https://api-inference.huggingface.co/models/facebook/mbart-large-50-many-to-many-mmt\"\n",
        "\n",
        "def traduzir_comentario(tcomentario):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=tcomentario) #função do HuggingFace\n",
        "\treturn response.json()"
      ],
      "metadata": {
        "id": "dmRKNn_E_ASS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Função para percorrer lista de comentários\n",
        "def traduzir(text):\n",
        "  data = {\"inputs\": text,\n",
        "           \"parameters\": {\n",
        "            \"src_lang\": \"en_XX\",\n",
        "            \"tgt_lang\": \"pt_XX\"\n",
        "                         }\n",
        "          }\n",
        "  response = traduzir_comentario(data) #chamada da função Hugging Face\n",
        "  return response[0]['translation_text']\n"
      ],
      "metadata": {
        "id": "ZVKpHLKh_dPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comentarios_amostra['traducao'] = comentarios_amostra[0].apply(traduzir)"
      ],
      "metadata": {
        "id": "YWOr7MLwAI-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comentarios_amostra"
      ],
      "metadata": {
        "id": "sk9n78u2AmrW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
